{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426447fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda1b80",
   "metadata": {},
   "source": [
    "The cell below outputs the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f3e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elang\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.13).\n",
      "Loading: C:\\Users\\elang\\.cache\\kagglehub\\datasets\\ahmedshahriarsakib\\usa-real-estate-dataset\\versions\\25\\realtor-data.zip.csv\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.10), please consider upgrading to the latest version (0.3.13).\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/danofer/zipcodes-county-fips-crosswalk?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184k/184k [00:00<00:00, 2.20MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Loading: C:\\Users\\elang\\.cache\\kagglehub\\datasets\\danofer\\zipcodes-county-fips-crosswalk\\versions\\1\\ZIP-COUNTY-FIPS_2017-06.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data_load import Data\n",
    "load = Data()\n",
    "load.HOMES_FOR_SALE()\n",
    "load.INCOME()\n",
    "load.HOMICIDES()\n",
    "load.POPULATION()\n",
    "load.ZIP_COUNTY()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Final_Data_Output import Final_Data as FD\n",
    "FD = FD()\n",
    "Master_df = FD.Merge_all(min_price=1000, max_bed=12, max_bath=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afd70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_tweedie_deviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "House_Income_Pop.dropna(axis=0, inplace=True)\n",
    "X = House_Income_Pop[['bed', 'bath', 'house_size', 'zip_code', 'acre_lot', 'Household_AGI', 'Total_Pop']]\n",
    "y = House_Income_Pop['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGReg = xgb_reg = xgb.XGBRegressor(\n",
    "    objective='reg:tweedie',\n",
    "    tweedie_variance_power=1.75, # Choose a value between 1 and 2 for overdispersed data\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "XGReg.fit(X_train, y_train)\n",
    "y_pred = XGReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61713702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Tweedie Deviance: 60.0778\n",
      "Null Model Mean Tweedie Deviance: 335.8737\n",
      "Percent Deviance Explained: 82.1130\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using the Mean Tweedie Deviance\n",
    "tweedie_deviance = mean_tweedie_deviance(y_test, y_pred, power=1.5)\n",
    "print(f\"Mean Tweedie Deviance: {tweedie_deviance:.4f}\")\n",
    "\n",
    "null_tweedie_deviance = mean_tweedie_deviance(y_test, [y_train.mean()]*len(y_test), power=1.5)\n",
    "print(f\"Null Model Mean Tweedie Deviance: {null_tweedie_deviance:.4f}\")\n",
    "print(f\"Percent Deviance Explained: {(1-tweedie_deviance/null_tweedie_deviance)*100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e441c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# 2. Ridge Regression (handles multicollinearity)\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "\n",
    "# 3. Lasso Regression (feature selection)\n",
    "lasso = Lasso(alpha=1.0)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "# 4. Elastic Net (combines Ridge + Lasso)\n",
    "elastic = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "elastic.fit(X_train, y_train)\n",
    "elastic_pred = elastic.predict(X_test)\n",
    "\n",
    "# 5. Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "# 6. Gradient Boosting\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "gb_pred = gb.predict(X_test)\n",
    "\n",
    "# 7. LightGBM (fast gradient boosting)\n",
    "lgb_reg = lgb.LGBMRegressor(n_estimators=100, random_state=42)\n",
    "lgb_reg.fit(X_train, y_train)\n",
    "lgb_pred = lgb_reg.predict(X_test)\n",
    "\n",
    "# 8. Support Vector Regression\n",
    "svr = SVR(kernel='rbf', C=1000, gamma='scale')\n",
    "svr.fit(X_train, y_train)\n",
    "svr_pred = svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models_dict, X_test, y_test, y_train):\n",
    "    \"\"\"Evaluate multiple models and return comparison metrics\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for name, predictions in models_dict.items():\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        tweedie = mean_tweedie_deviance(y_test, predictions, power=1.5)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'R²': r2,\n",
    "            'Tweedie_Deviance': tweedie\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('R²', ascending=False)\n",
    "\n",
    "# Compare all models\n",
    "models_predictions = {\n",
    "    'XGBoost': y_pred,\n",
    "    'Linear Regression': lr_pred,\n",
    "    'Ridge': ridge_pred,\n",
    "    'Lasso': lasso_pred,\n",
    "    'Elastic Net': elastic_pred,\n",
    "    'Random Forest': rf_pred,\n",
    "    'Gradient Boosting': gb_pred,\n",
    "    'LightGBM': lgb_pred,\n",
    "    'SVR': svr_pred\n",
    "}\n",
    "\n",
    "comparison_df = evaluate_models(models_predictions, X_test, y_test, y_train)\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d43953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Neural Network (MLPRegressor)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features for neural network\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "mlp_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "# 10. Polynomial Features + Linear Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "poly_lr = LinearRegression()\n",
    "poly_lr.fit(X_train_poly, y_train)\n",
    "poly_pred = poly_lr.predict(X_test_poly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
